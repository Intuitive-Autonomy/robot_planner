# utils.py (CSV trajectory dataset training)
from typing import List, Tuple
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader

# ---------- geometry ----------
def normalize_to_torso(joints: np.ndarray, arms: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    Normalize joints and arms relative to torso position
    joints: [T, 9, 3] or [9, 3]
    arms: [T, 4, 3] or [4, 3]
    """
    if joints.ndim == 2:  # Single frame
        torso_pos = joints[8]  # Index 8 = Torso
        joints_norm = joints - torso_pos[None, :]
        arms_norm = arms - torso_pos[None, :]
    else:  # Multiple frames
        torso_pos = joints[:, 8]  # [T, 3]
        joints_norm = joints - torso_pos[:, None, :]
        arms_norm = arms - torso_pos[:, None, :]
    return joints_norm, arms_norm

# ---------- CSV trajectory processor (OLD - not used) ----------
class CSVTrajectoryProcessor:
    def __init__(self, csv_path: str):
        self.df = pd.read_csv(csv_path)
        self.traj_ids = sorted(self.df['traj_id'].unique().tolist())

        # Define joint and arm columns
        self.joint_names = ['Head', 'Neck', 'R_Shoulder', 'L_Shoulder', 'R_Elbow', 'L_Elbow', 'R_Hand', 'L_Hand', 'Torso']
        self.joint_cols = []
        for joint in self.joint_names:
            self.joint_cols.extend([f"{joint}_pred_x", f"{joint}_pred_y", f"{joint}_pred_z"])

        self.arm_cols = [
            'Left_L1_x', 'Left_L1_y', 'Left_L1_z',
            'Left_L2_x', 'Left_L2_y', 'Left_L2_z',
            'Right_R1_x', 'Right_R1_y', 'Right_R1_z',
            'Right_R2_x', 'Right_R2_y', 'Right_R2_z'
        ]

        # Verify columns exist
        missing_joint_cols = [c for c in self.joint_cols if c not in self.df.columns]
        missing_arm_cols = [c for c in self.arm_cols if c not in self.df.columns]

        if missing_joint_cols:
            raise ValueError(f"Missing joint columns: {missing_joint_cols}")
        if missing_arm_cols:
            raise ValueError(f"Missing arm columns: {missing_arm_cols}")

        print(f"CSV Data: trajectories={len(self.traj_ids)}, frames={len(self.df)}, joints=27D, arms=12D")
    
    def get_trajectory_length(self, traj_id: int) -> int:
        """Get the number of frames in a trajectory"""
        traj_data = self.df[self.df['traj_id'] == traj_id]
        return len(traj_data)

    def get_trajectory_data(self, traj_id: int, normalize_to_torso_flag: bool = True, clip_arms_flag: bool = True):
        """
        Returns trajectory data for training
        Returns:
          joints [T,27]  : upper body joints (9 joints * 3 coords)
          arms [T,12]    : arm endpoints (4 endpoints * 3 coords)
        """
        # Get trajectory data sorted by frame_id
        traj_data = self.df[self.df['traj_id'] == traj_id].sort_values('frame_id')

        if len(traj_data) == 0:
            raise ValueError(f"No data found for trajectory {traj_id}")

        # Extract joint data [T, 27]
        joint_data = traj_data[self.joint_cols].values.astype(np.float32)  # [T, 27]
        joints = joint_data.reshape(-1, 9, 3)  # [T, 9, 3]

        # Extract arm data [T, 12]
        arm_data = traj_data[self.arm_cols].values.astype(np.float32)  # [T, 12]
        arms = arm_data.reshape(-1, 4, 3)  # [T, 4, 3]

        # Apply arm clipping
        if clip_arms_flag:
            arms = clip_arms_to_40cm(arms)

        # Apply torso normalization
        if normalize_to_torso_flag:
            joints, arms = normalize_to_torso(joints, arms)

        # Reshape back to 2D
        joints_2d = joints.reshape(-1, 27)  # [T, 27]
        arms_2d = arms.reshape(-1, 12)      # [T, 12]

        return joints_2d, arms_2d

# ---------- CSV trajectory dataset ----------
class CSVTrajectoryDataset(Dataset):
    def __init__(self,
                 csv_path: str,
                 traj_ids: List[int],
                 sequence_length: int = 30,
                 prediction_length: int = 10,
                 augment: bool = True,
                 rot_prob: float = 1.0,
                 scale_prob: float = 0.5,
                 scale_range: Tuple[float,float] = (0.9, 1.1),
                 time_scale_prob: float = 0.4,
                 time_scale_range: Tuple[float,float] = (0.8, 1.25),
                 noise_std_pos: float = 0.005):
        self.processor = CSVTrajectoryProcessor(csv_path)
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.augment = augment
        self.rot_prob = rot_prob
        self.scale_prob = scale_prob
        self.scale_range = scale_range
        self.time_scale_prob = time_scale_prob
        self.time_scale_range = time_scale_range
        self.noise_std_pos = noise_std_pos

        # Load trajectory data
        self.inputs, self.targets = [], []
        for traj_id in traj_ids:
            try:
                joints, arms = self.processor.get_trajectory_data(traj_id)
                self.inputs.append(joints)   # [T, 27]
                self.targets.append(arms)    # [T, 12]
            except ValueError as e:
                print(f"Warning: Could not load trajectory {traj_id}: {e}")
                continue

        # Create sequence windows
        self.sequences = []
        min_length = sequence_length + prediction_length
        for traj_idx, joints in enumerate(self.inputs):
            traj_length = joints.shape[0]
            if traj_length >= min_length:
                for start_idx in range(0, traj_length - min_length + 1):
                    self.sequences.append((traj_idx, start_idx))

        print(f"CSV Dataset: trajectories={len(traj_ids)}, loaded={len(self.inputs)}, sequences={len(self.sequences)}, "
              f"seq_len={sequence_length}, pred_len={prediction_length}, aug={'ON' if augment else 'OFF'}")

    def __len__(self):
        return len(self.sequences)

    # ---- augment ops ----
    def _apply_random_rotation(self, joints_seq, arms_seq):
        rq = random_rotation_quat()
        R = quat_to_rotmat(rq)

        joints_rot = joints_seq.copy()
        arms_rot = arms_seq.copy()

        # Rotate joints [T, 27] -> [T, 9, 3] -> rotate -> [T, 27]
        joints_3d = joints_seq.reshape(-1, 9, 3)
        joints_3d_rot = (joints_3d @ R.T)
        joints_rot = joints_3d_rot.reshape(-1, 27)

        # Rotate arms [T, 12] -> [T, 4, 3] -> rotate -> [T, 12]
        arms_3d = arms_seq.reshape(-1, 4, 3)
        arms_3d_rot = (arms_3d @ R.T)
        arms_rot = arms_3d_rot.reshape(-1, 12)

        return joints_rot, arms_rot

    def _apply_scale(self, joints_seq, arms_seq, scale_range):
        scale = np.random.uniform(scale_range[0], scale_range[1])
        joints_scaled = joints_seq.copy() * scale
        arms_scaled = arms_seq.copy() * scale
        return joints_scaled, arms_scaled

    def _apply_time_scale(self, joints_full, arms_full, seq_len, pred_len, scale_range):
        total_len = seq_len + pred_len
        scale = np.random.uniform(scale_range[0], scale_range[1])
        new_len = max(2, int(round(total_len * scale)))

        joints_resampled = resample_time(joints_full, new_len)
        arms_resampled = resample_time(arms_full, new_len)

        start = np.random.randint(0, max(1, new_len - total_len + 1))
        joints_seq = joints_resampled[start:start+seq_len]
        arms_seq = arms_resampled[start+seq_len:start+total_len]

        # Ensure correct lengths
        if joints_seq.shape[0] < seq_len:
            pad = np.repeat(joints_seq[-1:, :], seq_len - joints_seq.shape[0], axis=0)
            joints_seq = np.concatenate([joints_seq, pad], axis=0)
        joints_seq = joints_seq[:seq_len]

        if arms_seq.shape[0] < pred_len:
            pad = np.repeat(arms_seq[-1:, :], pred_len - arms_seq.shape[0], axis=0)
            arms_seq = np.concatenate([arms_seq, pad], axis=0)
        arms_seq = arms_seq[:pred_len]

        return joints_seq, arms_seq

    def __getitem__(self, idx: int):
        traj_idx, start_idx = self.sequences[idx]
        joints_full = self.inputs[traj_idx]  # [T, 27]
        arms_full = self.targets[traj_idx]   # [T, 12]

        end_input = start_idx + self.sequence_length
        end_all = end_input + self.prediction_length

        joints_seq = joints_full[start_idx:end_input].copy()    # [seq_len, 27]
        arms_seq = arms_full[end_input:end_all].copy()          # [pred_len, 12]

        if self.augment:
            # Time scaling augmentation
            if np.random.rand() < self.time_scale_prob:
                window_joints = joints_full[start_idx:end_all].copy()
                window_arms = arms_full[start_idx:end_all].copy()
                joints_seq, arms_seq = self._apply_time_scale(
                    window_joints, window_arms,
                    self.sequence_length, self.prediction_length,
                    self.time_scale_range
                )

            # Rotation augmentation
            if np.random.rand() < self.rot_prob:
                joints_seq, arms_seq = self._apply_random_rotation(joints_seq, arms_seq)

            # Scale augmentation
            if np.random.rand() < self.scale_prob:
                joints_seq, arms_seq = self._apply_scale(joints_seq, arms_seq, self.scale_range)

            # Add noise
            if self.noise_std_pos > 0:
                noise = np.random.normal(0.0, self.noise_std_pos, joints_seq.shape).astype(np.float32)
                joints_seq += noise

        return torch.from_numpy(joints_seq).float(), torch.from_numpy(arms_seq).float()

# ---------- CSV trajectory loaders ----------
def create_csv_data_loaders(csv_path: str,
                            batch_size: int = 32,
                            sequence_length: int = 30,
                            prediction_length: int = 10,
                            val_ratio: float = 0.2,
                            num_workers: int = 4):
    """Create data loaders for CSV trajectory dataset - using same data for train and val"""
    df = pd.read_csv(csv_path)
    traj_ids = sorted(df['traj_id'].unique().tolist())

    # Use ALL trajectories for both training and validation
    all_ids = traj_ids

    train_ds = CSVTrajectoryDataset(csv_path, all_ids, sequence_length, prediction_length, augment=True)
    val_ds = CSVTrajectoryDataset(csv_path, all_ids, sequence_length, prediction_length, augment=False)

    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)

    print(f"CSV Loaders: train={len(train_ds)}, val={len(val_ds)}, batch={batch_size}, seq_len={sequence_length}, pred_len={prediction_length}")
    print(f"Using same data for train and validation: {len(all_ids)} trajectories (traj_ids: {all_ids[:5]}...{all_ids[-3:]})")
    return train_loader, val_loader


# ---------- Trajectory-level training utils ----------
class TrajectoryTrainer:
    """Handles trajectory-level training with reduced teacher forcing"""
    def __init__(self, processor: CSVTrajectoryProcessor, traj_ids: List[int]):
        self.processor = processor
        self.traj_ids = traj_ids
        print(f"Trajectory Trainer: {len(traj_ids)} trajectories for trajectory-level training")

    def get_trajectory_batch(self, batch_traj_ids: List[int]):
        """Get full trajectories for trajectory-level training"""
        trajectories = []
        for traj_id in batch_traj_ids:
            try:
                joints, arms = self.processor.get_trajectory_data(traj_id)
                trajectories.append({
                    'traj_id': traj_id,
                    'joints': torch.from_numpy(joints).float(),  # [T, 27]
                    'arms': torch.from_numpy(arms).float()       # [T, 12]
                })
            except ValueError:
                continue
        return trajectories


# ========== Augmented Data Processing ==========
import os
import glob
from collections import defaultdict
from typing import Dict

def clip_robot_arms_to_40cm(arms: np.ndarray) -> np.ndarray:
    """
    Clip robot arm lengths to 40cm (400mm)
    arms: [T, 4, 3] or [4, 3] - [lback, lfront, rback, rfront]
    Rule: Keep back position fixed, clip front position to 400mm away from back
    """
    target_length = 400.0  # 40cm in mm

    if arms.ndim == 2:  # Single frame
        arms = arms[None, :]
        squeeze = True
    else:
        squeeze = False

    arms_clipped = arms.copy()

    for t in range(arms.shape[0]):
        # Left arm: lback -> lfront (indices 0 -> 1)
        back, front = arms[t, 0], arms[t, 1]
        vec = front - back
        length = np.linalg.norm(vec)
        if length > target_length:
            direction = vec / length
            arms_clipped[t, 1] = back + direction * target_length

        # Right arm: rback -> rfront (indices 2 -> 3)
        back, front = arms[t, 2], arms[t, 3]
        vec = front - back
        length = np.linalg.norm(vec)
        if length > target_length:
            direction = vec / length
            arms_clipped[t, 3] = back + direction * target_length

    if squeeze:
        arms_clipped = arms_clipped[0]

    return arms_clipped


class AugmentedDataProcessor:
    """
    Process augmented mocap data from global_csv directory
    - Handles 120fps -> 30fps downsampling
    - Extracts 9 upper body joints + 4 robot endpoints
    - Normalizes to torso and clips arms to 40cm
    """
    def __init__(self, data_root: str):
        """
        Args:
            data_root: Path to global_csv directory containing csv_*_augmented_processed folders
        """
        self.data_root = data_root
        self.file_groups = self._scan_augmented_files()
        print(f"Augmented Data: {len(self.file_groups)} base recordings, "
              f"{sum(len(files) for files in self.file_groups.values())} total files")

    def _scan_augmented_files(self) -> Dict[str, List[str]]:
        """
        Scan all augmented_processed directories and group files by base name
        Returns:
            {base_name: [aug_00.csv, aug_01.csv, ..., aug_09.csv]}
        """
        file_groups = defaultdict(list)

        # Scan all augmented_processed directories
        pattern = os.path.join(self.data_root, "csv_*_augmented_processed")
        aug_dirs = glob.glob(pattern)

        for aug_dir in aug_dirs:
            person_name = os.path.basename(aug_dir).replace("_augmented_processed", "")
            csv_files = glob.glob(os.path.join(aug_dir, "*.csv"))

            for csv_file in csv_files:
                filename = os.path.basename(csv_file)
                # Extract base name (remove _aug_XX.csv suffix)
                if "_aug_" in filename:
                    base_name = filename.rsplit("_aug_", 1)[0]
                    full_key = f"{person_name}/{base_name}"
                    file_groups[full_key].append(csv_file)

        # Sort files within each group to ensure consistent ordering
        for key in file_groups:
            file_groups[key] = sorted(file_groups[key])

        return dict(file_groups)

    def get_all_file_paths(self) -> List[str]:
        """Get all augmented CSV file paths"""
        all_files = []
        for files in self.file_groups.values():
            all_files.extend(files)
        return sorted(all_files)

    def get_base_names(self) -> List[str]:
        """Get all unique base recording names"""
        return sorted(list(self.file_groups.keys()))

    def load_trajectory_file(self, file_path: str, fps_target: int = 30,
                             normalize_to_torso_flag: bool = True,
                             clip_arms_flag: bool = True) -> Tuple[np.ndarray, np.ndarray]:
        """
        Load and process a single trajectory CSV file

        Args:
            file_path: Path to the CSV file
            fps_target: Target frame rate (default 30fps, original is 120fps)
            normalize_to_torso_flag: Whether to normalize to torso position
            clip_arms_flag: Whether to clip arms to 40cm

        Returns:
            inputs: [T, 39] - 9 joints (27D) + 4 robot endpoints (12D)
            targets: [T, 12] - 4 robot endpoints (clipped)
        """
        df = pd.read_csv(file_path)

        # Downsample from 120fps to target fps
        fps_original = 120
        downsample_factor = fps_original // fps_target
        df = df[::downsample_factor].reset_index(drop=True)

        # Extract 9 upper body joints in the order matching original data
        # Original order: [Head, Neck, R_Shoulder, L_Shoulder, R_Elbow, L_Elbow, R_Hand, L_Hand, Torso]
        # New data order: [torso, neck, head, l_shoulder, l_elbow, l_hand, r_shoulder, r_elbow, r_hand]
        joint_names_new = ['head', 'neck', 'r_shoulder', 'l_shoulder',
                           'r_elbow', 'l_elbow', 'r_hand', 'l_hand', 'torso']

        joints_list = []
        for joint_name in joint_names_new:
            x = df[f'{joint_name}:X'].values
            y = df[f'{joint_name}:Y'].values
            z = df[f'{joint_name}:Z'].values
            joints_list.append(np.stack([x, y, z], axis=1))

        joints = np.stack(joints_list, axis=1).astype(np.float32)  # [T, 9, 3]

        # Extract 4 robot endpoints: [lback, lfront, rback, rfront]
        robot_names = ['lback', 'lfront', 'rback', 'rfront']
        robot_list = []
        for robot_name in robot_names:
            x = df[f'{robot_name}:X'].values
            y = df[f'{robot_name}:Y'].values
            z = df[f'{robot_name}:Z'].values
            robot_list.append(np.stack([x, y, z], axis=1))

        robot_endpoints = np.stack(robot_list, axis=1).astype(np.float32)  # [T, 4, 3]

        # Clip robot arms to 40cm
        if clip_arms_flag:
            robot_endpoints_clipped = clip_robot_arms_to_40cm(robot_endpoints)
        else:
            robot_endpoints_clipped = robot_endpoints.copy()

        # Normalize to torso if requested
        if normalize_to_torso_flag:
            joints_norm, robot_norm = normalize_to_torso(joints, robot_endpoints_clipped)
        else:
            joints_norm = joints
            robot_norm = robot_endpoints_clipped

        # Prepare inputs: concatenate joints and robot endpoints
        # inputs: [T, 39] = joints [T, 27] + robot [T, 12]
        joints_2d = joints_norm.reshape(-1, 27)  # [T, 27]
        robot_2d = robot_norm.reshape(-1, 12)    # [T, 12]
        inputs = np.concatenate([joints_2d, robot_2d], axis=1)  # [T, 39]

        # targets: [T, 12] = robot endpoints (clipped)
        targets = robot_norm.reshape(-1, 12)  # [T, 12]

        return inputs, targets


class AugmentedDataset(Dataset):
    """
    Dataset for augmented mocap data with 8:1:1 train/val/test split
    Supports data augmentation (rotation, scaling, time scaling, progressive noise)

    Progressive Noise Strategy:
    - Skeleton (9 joints, 27D): Stage 1 (0→10mm), Stage 2 (10→30mm), Stage 3 (30→50mm)
    - Robot (4 points, 12D): Stage 1 (0→10mm), Stage 2 (10→20mm), Stage 3 (20→30mm)
    - Stage 3: + random spike noise (~200mm on 1-3 frames)
    """
    def __init__(self,
                 file_paths: List[str],
                 sequence_length: int = 30,
                 prediction_length: int = 10,
                 augment: bool = True,
                 rot_prob: float = 1.0,
                 scale_prob: float = 0.5,
                 scale_range: Tuple[float, float] = (0.9, 1.1),
                 time_scale_prob: float = 0.4,
                 time_scale_range: Tuple[float, float] = (0.8, 1.25),
                 noise_std_pos: float = 0.005,
                 noise_std_skeleton_mm: float = 0.0,
                 noise_std_robot_mm: float = 0.0,
                 noise_spike_prob: float = 0.0,
                 noise_spike_magnitude_mm: float = 200.0):
        """
        Args:
            file_paths: List of CSV file paths for this split
            sequence_length: Number of input frames
            prediction_length: Number of output frames
            augment: Whether to apply data augmentation
            noise_std_skeleton_mm: Std dev of skeleton noise (9 joints, first 27D)
            noise_std_robot_mm: Std dev of robot noise (4 points, last 12D)
        """
        self.file_paths = file_paths
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.augment = augment
        self.rot_prob = rot_prob
        self.scale_prob = scale_prob
        self.scale_range = scale_range
        self.time_scale_prob = time_scale_prob
        self.time_scale_range = time_scale_range
        self.noise_std_pos = noise_std_pos  # Legacy, kept for compatibility

        # Progressive noise parameters (separate for skeleton and robot)
        self.noise_std_skeleton_mm = noise_std_skeleton_mm
        self.noise_std_robot_mm = noise_std_robot_mm
        self.noise_spike_prob = noise_spike_prob
        self.noise_spike_magnitude_mm = noise_spike_magnitude_mm

        # Load all trajectories
        self.inputs_list = []   # List of [T, 39] arrays
        self.targets_list = []  # List of [T, 12] arrays

        processor = AugmentedDataProcessor(os.path.dirname(os.path.dirname(file_paths[0])))

        for file_path in file_paths:
            try:
                inputs, targets = processor.load_trajectory_file(file_path)
                self.inputs_list.append(inputs)
                self.targets_list.append(targets)
            except Exception as e:
                print(f"Warning: Failed to load {file_path}: {e}")
                continue

        # Create sliding windows
        self.sequences = []
        min_length = sequence_length + prediction_length

        for traj_idx, inputs in enumerate(self.inputs_list):
            traj_length = inputs.shape[0]
            if traj_length >= min_length:
                for start_idx in range(0, traj_length - min_length + 1):
                    self.sequences.append((traj_idx, start_idx))

        print(f"Augmented Dataset: files={len(file_paths)}, loaded={len(self.inputs_list)}, "
              f"sequences={len(self.sequences)}, seq_len={sequence_length}, "
              f"pred_len={prediction_length}, aug={'ON' if augment else 'OFF'}")

    def __len__(self):
        return len(self.sequences)

    def _apply_random_rotation(self, inputs_seq, targets_seq):
        """Apply random 3D rotation to both inputs and targets"""
        rq = random_rotation_quat()
        R = quat_to_rotmat(rq)

        # Rotate inputs [T, 39] -> [T, 13, 3]
        inputs_3d = inputs_seq.reshape(-1, 13, 3)
        inputs_rot = (inputs_3d @ R.T).reshape(-1, 39)

        # Rotate targets [T, 12] -> [T, 4, 3]
        targets_3d = targets_seq.reshape(-1, 4, 3)
        targets_rot = (targets_3d @ R.T).reshape(-1, 12)

        return inputs_rot, targets_rot

    def _apply_scale(self, inputs_seq, targets_seq, scale_range):
        """Apply random uniform scaling"""
        scale = np.random.uniform(scale_range[0], scale_range[1])
        return inputs_seq * scale, targets_seq * scale

    def _apply_time_scale(self, inputs_full, targets_full, seq_len, pred_len, scale_range):
        """Apply random time scaling (speed up/slow down)"""
        total_len = seq_len + pred_len
        scale = np.random.uniform(scale_range[0], scale_range[1])
        new_len = max(2, int(round(total_len * scale)))

        inputs_resampled = resample_time(inputs_full, new_len)
        targets_resampled = resample_time(targets_full, new_len)

        start = np.random.randint(0, max(1, new_len - total_len + 1))
        inputs_seq = inputs_resampled[start:start+seq_len]
        targets_seq = targets_resampled[start+seq_len:start+total_len]

        # Ensure correct lengths with padding if needed
        if inputs_seq.shape[0] < seq_len:
            pad = np.repeat(inputs_seq[-1:, :], seq_len - inputs_seq.shape[0], axis=0)
            inputs_seq = np.concatenate([inputs_seq, pad], axis=0)
        inputs_seq = inputs_seq[:seq_len]

        if targets_seq.shape[0] < pred_len:
            pad = np.repeat(targets_seq[-1:, :], pred_len - targets_seq.shape[0], axis=0)
            targets_seq = np.concatenate([targets_seq, pad], axis=0)
        targets_seq = targets_seq[:pred_len]

        return inputs_seq, targets_seq

    def _apply_progressive_noise(self, inputs_seq):
        """
        Apply progressive trajectory-level noise with separate parameters for skeleton and robot
        - Trajectory-level: same noise offset for entire sequence
        - Skeleton (first 27D): uses noise_std_skeleton_mm
        - Robot (last 12D): uses noise_std_robot_mm
        - Spike noise: random large noise on 1-3 frames in stage 3

        Args:
            inputs_seq: [T, 39] input sequence (27D skeleton + 12D robot)

        Returns:
            noisy_inputs: [T, 39] with noise applied
        """
        if self.noise_std_skeleton_mm == 0 and self.noise_std_robot_mm == 0:
            return inputs_seq

        T = inputs_seq.shape[0]
        noisy_inputs = inputs_seq.copy()

        # Split into skeleton (27D) and robot (12D)
        skeleton = noisy_inputs[:, :27]  # [T, 27]
        robot = noisy_inputs[:, 27:]     # [T, 12]

        # Apply trajectory-level noise to skeleton
        if self.noise_std_skeleton_mm > 0:
            # Trajectory-level offset (shared across all frames)
            traj_offset_skel = np.random.normal(0.0, self.noise_std_skeleton_mm, size=(1, 27)).astype(np.float32)
            # Per-frame independent noise
            per_frame_skel = np.random.normal(0.0, self.noise_std_skeleton_mm, size=(T, 27)).astype(np.float32)
            skeleton += traj_offset_skel + per_frame_skel

        # Apply trajectory-level noise to robot
        if self.noise_std_robot_mm > 0:
            # Trajectory-level offset (shared across all frames)
            traj_offset_robot = np.random.normal(0.0, self.noise_std_robot_mm, size=(1, 12)).astype(np.float32)
            # Per-frame independent noise
            per_frame_robot = np.random.normal(0.0, self.noise_std_robot_mm, size=(T, 12)).astype(np.float32)
            robot += traj_offset_robot + per_frame_robot

        # Recombine
        noisy_inputs = np.concatenate([skeleton, robot], axis=1)

        # Stage 3: Add spike noise to random frames (applies to all 39D)
        if self.noise_spike_prob > 0 and np.random.rand() < self.noise_spike_prob:
            # Randomly select 1-3 frames
            num_spike_frames = np.random.randint(1, 4)
            spike_frame_indices = np.random.choice(T, size=num_spike_frames, replace=False)

            # Add large spike noise to selected frames
            for frame_idx in spike_frame_indices:
                spike_noise = np.random.normal(0.0, self.noise_spike_magnitude_mm, size=(39,)).astype(np.float32)
                noisy_inputs[frame_idx] += spike_noise

        return noisy_inputs

    def __getitem__(self, idx: int):
        traj_idx, start_idx = self.sequences[idx]
        inputs_full = self.inputs_list[traj_idx]    # [T, 39]
        targets_full = self.targets_list[traj_idx]  # [T, 12]

        end_input = start_idx + self.sequence_length
        end_all = end_input + self.prediction_length

        inputs_seq = inputs_full[start_idx:end_input].copy()   # [seq_len, 39]
        targets_seq = targets_full[end_input:end_all].copy()   # [pred_len, 12]

        if self.augment:
            # Time scaling augmentation
            if np.random.rand() < self.time_scale_prob:
                window_inputs = inputs_full[start_idx:end_all].copy()
                window_targets = targets_full[start_idx:end_all].copy()
                inputs_seq, targets_seq = self._apply_time_scale(
                    window_inputs, window_targets,
                    self.sequence_length, self.prediction_length,
                    self.time_scale_range
                )

            # Rotation augmentation
            if np.random.rand() < self.rot_prob:
                inputs_seq, targets_seq = self._apply_random_rotation(inputs_seq, targets_seq)

            # Scale augmentation
            if np.random.rand() < self.scale_prob:
                inputs_seq, targets_seq = self._apply_scale(inputs_seq, targets_seq, self.scale_range)

            # Add progressive trajectory-level noise
            inputs_seq = self._apply_progressive_noise(inputs_seq)

        return torch.from_numpy(inputs_seq).float(), torch.from_numpy(targets_seq).float()


def create_augmented_data_loaders(data_root: str,
                                   batch_size: int = 32,
                                   sequence_length: int = 30,
                                   prediction_length: int = 10,
                                   train_ratio: float = 0.8,
                                   val_ratio: float = 0.1,
                                   test_ratio: float = 0.1,
                                   num_workers: int = 4,
                                   random_seed: int = 42,
                                   noise_std_skeleton_mm: float = 0.0,
                                   noise_std_robot_mm: float = 0.0,
                                   noise_spike_prob: float = 0.0,
                                   noise_spike_magnitude_mm: float = 200.0):
    """
    Create train/val/test data loaders for augmented data with 8:1:1 split
    Ensures no data leakage: all 10 augmented versions of the same recording
    are only in one split (train/val/test)

    Args:
        data_root: Path to global_csv directory
        batch_size: Batch size for training
        sequence_length: Number of input frames
        prediction_length: Number of prediction frames
        train_ratio: Ratio of base recordings for training (default 0.8)
        val_ratio: Ratio for validation (default 0.1)
        test_ratio: Ratio for testing (default 0.1)
        num_workers: Number of data loading workers
        random_seed: Random seed for reproducible splits
        noise_std_skeleton_mm: Std dev of skeleton noise in mm (default 0.0)
        noise_std_robot_mm: Std dev of robot noise in mm (default 0.0)
        noise_spike_prob: Probability of adding spike noise (default 0.0)
        noise_spike_magnitude_mm: Magnitude of spike noise in mm (default 200.0)

    Returns:
        train_loader, val_loader, test_loader
    """
    processor = AugmentedDataProcessor(data_root)
    base_names = processor.get_base_names()
    file_groups = processor.file_groups

    # Shuffle base names with fixed seed for reproducibility
    np.random.seed(random_seed)
    shuffled_bases = np.random.permutation(base_names).tolist()

    # Calculate split indices
    n_total = len(shuffled_bases)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)

    # Split base names
    train_bases = shuffled_bases[:n_train]
    val_bases = shuffled_bases[n_train:n_train+n_val]
    test_bases = shuffled_bases[n_train+n_val:]

    # Expand to file paths (each base has 10 augmented files)
    train_files = [f for base in train_bases for f in file_groups[base]]
    val_files = [f for base in val_bases for f in file_groups[base]]
    test_files = [f for base in test_bases for f in file_groups[base]]

    print(f"\nAugmented Data Split:")
    print(f"  Total base recordings: {n_total}")
    print(f"  Train: {len(train_bases)} bases ({len(train_files)} files)")
    print(f"  Val:   {len(val_bases)} bases ({len(val_files)} files)")
    print(f"  Test:  {len(test_bases)} bases ({len(test_files)} files)")

    # Create datasets (only apply progressive noise to training set)
    train_ds = AugmentedDataset(train_files, sequence_length, prediction_length, augment=True,
                                noise_std_skeleton_mm=noise_std_skeleton_mm,
                                noise_std_robot_mm=noise_std_robot_mm,
                                noise_spike_prob=noise_spike_prob,
                                noise_spike_magnitude_mm=noise_spike_magnitude_mm)
    val_ds = AugmentedDataset(val_files, sequence_length, prediction_length, augment=False,
                              noise_std_skeleton_mm=0.0, noise_std_robot_mm=0.0,
                              noise_spike_prob=0.0, noise_spike_magnitude_mm=0.0)
    test_ds = AugmentedDataset(test_files, sequence_length, prediction_length, augment=False,
                               noise_std_skeleton_mm=0.0, noise_std_robot_mm=0.0,
                               noise_spike_prob=0.0, noise_spike_magnitude_mm=0.0)

    # Create data loaders
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,
                              num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,
                            num_workers=num_workers, pin_memory=True)
    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,
                             num_workers=num_workers, pin_memory=True)

    print(f"\nData Loaders Created:")
    print(f"  Train: {len(train_ds)} sequences, {len(train_loader)} batches")
    print(f"  Val:   {len(val_ds)} sequences, {len(val_loader)} batches")
    print(f"  Test:  {len(test_ds)} sequences, {len(test_loader)} batches")

    return train_loader, val_loader, test_loader


# ==================== Advanced Data Augmentation (from validated test) ====================

def plane_normal(points):
    """计算点集的平面法向量"""
    C = points.mean(axis=0)
    X = points - C
    _, _, Vt = np.linalg.svd(X, full_matrices=False)
    n = Vt[-1, :]
    n /= np.linalg.norm(n) + 1e-12
    return n


def rot_from_two_vectors(a, b):
    """计算从向量a旋转到向量b的旋转矩阵"""
    a = a / (np.linalg.norm(a) + 1e-12)
    b = b / (np.linalg.norm(b) + 1e-12)
    v = np.cross(a, b)
    c = float(np.dot(a, b))
    s = np.linalg.norm(v)

    if s < 1e-12:
        if c > 0:
            return np.eye(3)
        # 180度旋转
        axis = np.array([1.0, 0.0, 0.0])
        if abs(a[0]) > 0.9:
            axis = np.array([0.0, 1.0, 0.0])
        axis = axis - axis.dot(a) * a
        axis /= np.linalg.norm(axis) + 1e-12
        # Rodrigues公式：180度旋转
        K = np.array([[0, -axis[2], axis[1]],
                     [axis[2], 0, -axis[0]],
                     [-axis[1], axis[0], 0]])
        return np.eye(3) + 2 * K @ K

    vx = np.array([[0, -v[2], v[1]],
                   [v[2], 0, -v[0]],
                   [-v[1], v[0], 0]])
    return np.eye(3) + vx + vx @ vx * ((1 - c) / (s**2 + 1e-12))


def kabsch_rigid_transform(A, B):
    """计算从A到B的刚体变换（旋转+平移）"""
    A = np.asarray(A, dtype=float)
    B = np.asarray(B, dtype=float)
    assert A.shape == B.shape and A.shape[1] == 3

    centroid_A = A.mean(axis=0)
    centroid_B = B.mean(axis=0)
    AA = A - centroid_A
    BB = B - centroid_B
    H = AA.T @ BB
    U, S, Vt = np.linalg.svd(H)
    R = Vt.T @ U.T
    if np.linalg.det(R) < 0:
        Vt[-1, :] *= -1
        R = Vt.T @ U.T
    t = centroid_B - R @ centroid_A
    return R, t


def mat_to_axis_angle(R):
    """旋转矩阵转轴角"""
    tr = np.trace(R)
    cos_theta = max(-1.0, min(1.0, (tr - 1.0) / 2.0))
    theta = np.arccos(cos_theta)
    if theta < 1e-12:
        return np.array([1.0, 0.0, 0.0]), 0.0
    axis = np.array([R[2, 1] - R[1, 2],
                     R[0, 2] - R[2, 0],
                     R[1, 0] - R[0, 1]]) / (2 * np.sin(theta))
    axis /= np.linalg.norm(axis) + 1e-12
    return axis, theta


def rodrigues(axis, angle):
    """Rodrigues公式：轴角到旋转矩阵"""
    axis = axis / (np.linalg.norm(axis) + 1e-12)
    K = np.array([[0, -axis[2], axis[1]],
                  [axis[2], 0, -axis[0]],
                  [-axis[1], axis[0], 0]])
    return np.eye(3) + np.sin(angle) * K + (1 - np.cos(angle)) * (K @ K)


def slerp_R(R, s):
    """球面线性插值旋转矩阵"""
    axis, ang = mat_to_axis_angle(R)
    return rodrigues(axis, s * ang)


def sample_arm_start_pose(original_arms, head_pos, original_distance, y_fixed=1000.0, half_angle_deg=15.0):
    """
    采样机械臂起始姿态（位置+朝向）

    Args:
        original_arms: [4, 3] 原始机械臂端点 [L1, L2, R1, R2]
        head_pos: [3] 头部位置
        original_distance: float 原始head到臂中点距离
        y_fixed: float 固定的Y高度
        half_angle_deg: float 锥形半角（度）

    Returns:
        sampled_arms: [4, 3] 采样后的机械臂端点
        sampled_mid: [3] 采样的中点位置
        sampled_distance: float 采样距离
    """
    # 原始中点和方向
    mid_orig = original_arms.mean(axis=0)
    ref_dir = mid_orig - head_pos
    ref_norm = np.linalg.norm(ref_dir)
    if ref_norm < 1e-9:
        ref_dir = np.array([0, 0, 1.0])
        ref_norm = 1.0
    ref_dir_unit = ref_dir / ref_norm

    # 采样距离：原距离 ~ 2000mm
    sampled_distance = np.random.uniform(original_distance, 2000.0)

    # 在锥形内采样方向（球坐标）
    half_angle_rad = np.deg2rad(half_angle_deg)
    theta = np.random.uniform(0.0, 2.0 * np.pi)
    u = np.random.uniform(np.cos(half_angle_rad), 1.0)
    phi = np.arccos(u)

    # 构造局部坐标系
    z = ref_dir_unit
    tmp = np.array([1.0, 0.0, 0.0]) if abs(z[2]) > 0.9 else np.array([0.0, 0.0, 1.0])
    x = np.cross(tmp, z)
    x /= np.linalg.norm(x) + 1e-12
    y = np.cross(z, x)

    # 采样方向
    dir_vec = (np.sin(phi) * np.cos(theta)) * x + \
              (np.sin(phi) * np.sin(theta)) * y + \
              (np.cos(phi)) * z

    # 采样中点位置
    mid_new = head_pos + sampled_distance * dir_vec
    mid_new[1] = y_fixed  # 固定Y高度

    # 计算原始平面法向量
    n_orig = plane_normal(original_arms)

    # 目标法向量：平行于XZ平面，选择-Y方向（相机在下方）
    e_y = np.array([0.0, 1.0, 0.0])
    R_align = rot_from_two_vectors(n_orig, -e_y)

    # 应用旋转并平移到新中点
    C_orig = original_arms.mean(axis=0)
    sampled_arms = (R_align @ (original_arms - C_orig).T).T + mid_new

    return sampled_arms, mid_new, sampled_distance


def interpolate_robot_rigid_trajectory(start_arms, target_arms, max_speed=10.0):
    """
    使用刚体变换插值机器人轨迹

    Args:
        start_arms: [4, 3] 起始机械臂姿态 [L1, L2, R1, R2]
        target_arms: [4, 3] 目标机械臂姿态
        max_speed: float 最大速度 mm/frame

    Returns:
        interp_arms: [n_frames, 12] 插值后的机械臂轨迹
        n_frames: int 帧数
    """
    # 计算刚体变换：start -> target
    R, t = kabsch_rigid_transform(start_arms, target_arms)

    # 计算最大位移（用于确定帧数）
    disp = np.linalg.norm(target_arms - start_arms, axis=1)
    max_disp = float(np.max(disp)) if disp.size else 0.0

    # 计算帧数
    n_frames = max(1, int(max_disp / max_speed) + 1)

    # 刚体插值
    interp_arms = []
    for i in range(n_frames):
        s = (i + 1) / n_frames
        Ri = slerp_R(R, s)
        ti = s * t
        Pi = (Ri @ start_arms.T).T + ti  # [4, 3]
        interp_arms.append(Pi.reshape(-1))  # [12]

    return np.array(interp_arms), n_frames


def generate_flipped_human_trajectory(joints, phases, n_frames, noise_std=2.0):
    """
    生成对应的人体姿态序列（翻转approaching前2/3 + 噪声）

    Args:
        joints: [T, 27] 原始关节数据
        phases: [T] 阶段标签
        n_frames: int 需要生成的帧数
        noise_std: float 噪声标准差(mm)

    Returns:
        human_traj: [n_frames, 27] 人体姿态序列
    """
    # 提取approaching阶段
    approach_mask = (phases == 0)
    approach_joints = joints[approach_mask]

    if len(approach_joints) == 0:
        # 如果没有approaching阶段，使用前30帧
        approach_joints = joints[:30]

    # 取前2/3部分
    n_use = max(1, int(len(approach_joints) * 2/3))
    selected_joints = approach_joints[:n_use]

    # 时间翻转
    flipped_joints = selected_joints[::-1]

    # 重采样到n_frames
    if len(flipped_joints) >= n_frames:
        human_traj = flipped_joints[:n_frames]
    else:
        # 线性插值
        t_old = np.linspace(0, 1, len(flipped_joints))
        t_new = np.linspace(0, 1, n_frames)
        human_traj = np.zeros((n_frames, 27))
        for d in range(27):
            human_traj[:, d] = np.interp(t_new, t_old, flipped_joints[:, d])

    # 添加噪声
    noise = np.random.normal(0, noise_std, human_traj.shape)
    human_traj = human_traj + noise

    return human_traj


def augment_initial_position(joints, arms, phases, head_pos, y_fixed=1000.0, half_angle_deg=15.0, max_speed=10.0, noise_std=2.0):
    """
    完整的初始位置数据增强（已验证版本）

    Args:
        joints: [T, 27] 人体关节数据
        arms: [T, 12] 机械臂数据
        phases: [T] 阶段标签
        head_pos: [3] 头部位置
        y_fixed: float 固定的Y高度
        half_angle_deg: float 锥形半角
        max_speed: float 最大速度mm/frame
        noise_std: float 人体噪声std(mm)

    Returns:
        aug_joints: [T_aug, 27] 增强后的人体关节
        aug_arms: [T_aug, 12] 增强后的机械臂
        aug_phases: [T_aug] 增强后的阶段标签
        n_aug_frames: int 增强帧数
    """
    # 1. 提取原始机械臂姿态
    original_arms_3d = arms[0].reshape(4, 3)  # [L1, L2, R1, R2]
    original_mid = original_arms_3d.mean(axis=0)
    original_distance = np.linalg.norm(original_mid - head_pos)

    # 2. 采样新起始姿态
    start_arms, sampled_mid, sampled_distance = sample_arm_start_pose(
        original_arms_3d, head_pos, original_distance,
        y_fixed=y_fixed, half_angle_deg=half_angle_deg
    )

    # 3. 使用刚体变换插值轨迹
    interp_arms, n_frames = interpolate_robot_rigid_trajectory(
        start_arms, original_arms_3d, max_speed=max_speed
    )

    # 4. 生成人体姿态
    human_traj = generate_flipped_human_trajectory(joints, phases, n_frames, noise_std=noise_std)

    # 5. 生成phase标签（全部为approaching）
    phase_prefix = np.zeros(n_frames, dtype=int)

    # 6. 拼接
    aug_joints = np.vstack([human_traj, joints])
    aug_arms = np.vstack([interp_arms, arms])
    aug_phases = np.concatenate([phase_prefix, phases])

    return aug_joints, aug_arms, aug_phases, n_frames


def rotate_y_axis(joints, arms, angle=None):
    """
    Y轴旋转数据增强

    Args:
        joints: [T, 27] or [T, 9, 3]
        arms: [T, 12] or [T, 4, 3]
        angle: float (radians), None表示随机

    Returns:
        joints_rot, arms_rot
    """
    if angle is None:
        angle = np.random.uniform(0, 2*np.pi)

    cos_a, sin_a = np.cos(angle), np.sin(angle)
    R = np.array([[cos_a, 0, sin_a],
                  [0, 1, 0],
                  [-sin_a, 0, cos_a]], dtype=np.float32)

    # Reshape if needed
    joints_3d = joints.reshape(-1, 9, 3) if joints.shape[-1] != 3 else joints
    arms_3d = arms.reshape(-1, 4, 3) if arms.shape[-1] != 3 else arms

    # 旋转
    joints_rot = (R @ joints_3d.reshape(-1, 3).T).T.reshape(joints_3d.shape)
    arms_rot = (R @ arms_3d.reshape(-1, 3).T).T.reshape(arms_3d.shape)

    # Reshape back
    if joints.shape[-1] != 3:
        joints_rot = joints_rot.reshape(-1, 27)
    if arms.shape[-1] != 3:
        arms_rot = arms_rot.reshape(-1, 12)

    return joints_rot, arms_rot


def time_scale_augmentation(joints, arms, phases, scale_range=(0.9, 1.1)):
    """
    时间尺度缩放数据增强

    Args:
        joints: [T, 27]
        arms: [T, 12]
        phases: [T]
        scale_range: (min_scale, max_scale)

    Returns:
        joints_scaled, arms_scaled, phases_scaled
    """
    T = len(joints)
    scale = np.random.uniform(scale_range[0], scale_range[1])
    T_new = int(T * scale)
    T_new = max(10, T_new)  # 至少10帧

    t_old = np.linspace(0, 1, T)
    t_new = np.linspace(0, 1, T_new)

    # 插值关节
    joints_scaled = np.zeros((T_new, 27))
    for d in range(27):
        joints_scaled[:, d] = np.interp(t_new, t_old, joints[:, d])

    # 插值机械臂
    arms_scaled = np.zeros((T_new, 12))
    for d in range(12):
        arms_scaled[:, d] = np.interp(t_new, t_old, arms[:, d])

    # 插值phases（最近邻）
    phase_indices = np.interp(t_new, t_old, np.arange(T)).astype(int)
    phase_indices = np.clip(phase_indices, 0, T-1)
    phases_scaled = phases[phase_indices]

    return joints_scaled, arms_scaled, phases_scaled


# ==================== CSV Trajectory Dataset with Phase ====================

class CSVTrajectoryDataset(Dataset):
    """
    Dataset for CSV trajectory files with phase labels
    Supports: GT/Pred data, all augmentations, phase labels
    """
    def __init__(self, csv_files, sequence_length=30, prediction_length=10,
                 use_gt=True, augmentation_config=None):
        """
        Args:
            csv_files: List of CSV file paths
            sequence_length: Input sequence length
            prediction_length: Prediction length
            use_gt: True=use GT poses, False=use Pred poses
            augmentation_config: Dict with keys:
                - rotate_prob: float
                - time_scale_prob: float
                - initial_pos_prob: float
                - noise_std: float
        """
        self.csv_files = csv_files
        self.sequence_length = sequence_length
        self.prediction_length = prediction_length
        self.use_gt = use_gt
        self.aug_cfg = augmentation_config or {}

        # Joint names (9 joints used for network input)
        self.joint_names = ['Head', 'Neck', 'R_Shoulder', 'L_Shoulder',
                           'R_Elbow', 'L_Elbow', 'R_Hand', 'L_Hand', 'Torso']

        # Load all trajectories
        self.trajectories = []
        self._load_all_trajectories()

    def set_augmentation_config(self, augmentation_config):
        """Update augmentation config without reloading data"""
        self.aug_cfg = augmentation_config or {}

    def _load_all_trajectories(self):
        """Load all CSV files and create overlapping trajectory segments"""
        suffix = '_gt' if self.use_gt else '_pred'
        min_length = self.sequence_length + self.prediction_length
        stride = 1  # Use every frame as starting point for maximum data utilization

        for csv_file in self.csv_files:
            try:
                df = pd.read_csv(csv_file)
                traj_ids = df['traj_id'].unique()

                for traj_id in traj_ids:
                    traj_df = df[df['traj_id'] == traj_id].sort_values('frame_id').reset_index(drop=True)

                    # Extract joints [T, 27]
                    joint_cols = []
                    for jname in self.joint_names:
                        joint_cols.extend([f'{jname}{suffix}_x', f'{jname}{suffix}_y', f'{jname}{suffix}_z'])
                    joints = traj_df[joint_cols].values.astype(np.float32)

                    # Extract arms [T, 12]
                    arm_cols = ['Left_L1_x', 'Left_L1_y', 'Left_L1_z',
                               'Left_L2_x', 'Left_L2_y', 'Left_L2_z',
                               'Right_R1_x', 'Right_R1_y', 'Right_R1_z',
                               'Right_R2_x', 'Right_R2_y', 'Right_R2_z']
                    arms = traj_df[arm_cols].values.astype(np.float32)

                    # Extract phases [T]
                    phase_col = f'phase{suffix}' if f'phase{suffix}' in traj_df.columns else 'phase_gt'
                    phases = traj_df[phase_col].values.astype(np.int64)

                    # Extract head position for augmentation
                    head_pos = np.array([
                        traj_df[f'Head{suffix}_x'].values[0],
                        traj_df[f'Head{suffix}_y'].values[0],
                        traj_df[f'Head{suffix}_z'].values[0]
                    ], dtype=np.float32)

                    # Create overlapping segments with stride
                    T = len(joints)
                    if T < min_length:
                        # If trajectory too short, pad and create one segment
                        pad_len = min_length - T
                        joints_padded = np.vstack([joints, np.tile(joints[-1:], (pad_len, 1))])
                        arms_padded = np.vstack([arms, np.tile(arms[-1:], (pad_len, 1))])
                        phases_padded = np.concatenate([phases, np.tile(phases[-1:], pad_len)])

                        self.trajectories.append({
                            'joints': joints_padded,
                            'arms': arms_padded,
                            'phases': phases_padded,
                            'head_pos': head_pos,
                            'traj_id': traj_id,
                            'file': csv_file,
                            'start_idx': 0
                        })
                    else:
                        # Create multiple overlapping segments
                        for start_idx in range(0, T - min_length + 1, stride):
                            self.trajectories.append({
                                'joints': joints,
                                'arms': arms,
                                'phases': phases,
                                'head_pos': head_pos,
                                'traj_id': traj_id,
                                'file': csv_file,
                                'start_idx': start_idx
                            })

            except Exception as e:
                print(f"Warning: Failed to load {csv_file}: {e}")
                continue

        print(f"Loaded {len(self.trajectories)} segments from {len(self.csv_files)} files")

    def __len__(self):
        return len(self.trajectories)

    def __getitem__(self, idx):
        traj = self.trajectories[idx]
        joints = traj['joints'].copy()  # [T, 27]
        arms = traj['arms'].copy()      # [T, 12]
        phases = traj['phases'].copy()  # [T]
        head_pos = traj['head_pos'].copy()
        start_idx = traj['start_idx']  # Pre-determined start index

        # Apply augmentations
        length_changed = False

        if self.aug_cfg.get('rotate_prob', 0) > 0 and np.random.rand() < self.aug_cfg['rotate_prob']:
            joints, arms = rotate_y_axis(joints, arms)

        if self.aug_cfg.get('time_scale_prob', 0) > 0 and np.random.rand() < self.aug_cfg['time_scale_prob']:
            joints, arms, phases = time_scale_augmentation(joints, arms, phases)
            length_changed = True

        if self.aug_cfg.get('initial_pos_prob', 0) > 0 and np.random.rand() < self.aug_cfg['initial_pos_prob']:
            joints, arms, phases, _ = augment_initial_position(joints, arms, phases, head_pos)
            length_changed = True

        # Add noise
        if self.aug_cfg.get('noise_std', 0) > 0:
            noise = np.random.normal(0, self.aug_cfg['noise_std'], joints.shape).astype(np.float32)
            joints = joints + noise

        # Extract segment (40 consecutive frames total)
        min_length = self.sequence_length + self.prediction_length

        # If augmentation changed length, randomly select new start_idx
        if length_changed:
            T = len(joints)
            if T < min_length:
                # Pad if too short
                pad_len = min_length - T
                joints = np.vstack([joints, np.tile(joints[-1:], (pad_len, 1))])
                arms = np.vstack([arms, np.tile(arms[-1:], (pad_len, 1))])
                phases = np.concatenate([phases, np.tile(phases[-1:], pad_len)])
                start_idx = 0
            else:
                # Randomly select start index
                max_start = T - min_length
                start_idx = np.random.randint(0, max_start + 1) if max_start > 0 else 0

        # Extract input and target segments
        input_joints = joints[start_idx:start_idx + self.sequence_length]  # [30, 27]
        input_arms = arms[start_idx:start_idx + self.sequence_length]      # [30, 12]
        target_arms = arms[start_idx + self.sequence_length:start_idx + min_length]  # [10, 12]
        target_phases = phases[start_idx + self.sequence_length:start_idx + min_length]  # [10]

        # Reshape for normalization
        input_joints_3d = input_joints.reshape(self.sequence_length, 9, 3)  # [30, 9, 3]
        input_arms_3d = input_arms.reshape(self.sequence_length, 4, 3)      # [30, 4, 3]
        target_arms_3d = target_arms.reshape(self.prediction_length, 4, 3)  # [10, 4, 3]

        # Normalize to torso coordinate system (like in robot_planner)
        normalized_input_joints, normalized_input_arms = normalize_to_torso(input_joints_3d, input_arms_3d)

        # For target arms, use the last frame's torso position from input window
        torso_positions = input_joints_3d[:, 8, :]  # [30, 3]
        last_torso = torso_positions[-1:, :]  # [1, 3] - last frame's torso
        # Normalize target arms relative to last input torso
        normalized_target_arms = target_arms_3d - last_torso[None, :, :]  # [10, 4, 3]

        # Flatten back
        normalized_input_joints_flat = normalized_input_joints.reshape(self.sequence_length, -1)  # [30, 27]
        normalized_input_arms_flat = normalized_input_arms.reshape(self.sequence_length, -1)      # [30, 12]
        normalized_target_arms_flat = normalized_target_arms.reshape(self.prediction_length, -1)  # [10, 12]

        # Concatenate input: [30, 27+12=39]
        input_seq = np.concatenate([normalized_input_joints_flat, normalized_input_arms_flat], axis=1)

        return (torch.from_numpy(input_seq).float(),
                torch.from_numpy(normalized_target_arms_flat).float(),
                torch.from_numpy(target_phases).long())


def create_csv_data_loaders(gt_csv_files, pred_csv_files,
                            sequence_length=30, prediction_length=10,
                            batch_size=64, num_workers=4,
                            gt_ratio=1.0, augmentation_config=None,
                            train_ratio=0.8, val_ratio=0.1):
    """
    Create DataLoaders for CSV trajectory training

    Args:
        gt_csv_files: List of GT CSV files
        pred_csv_files: List of Pred CSV files
        gt_ratio: Ratio of GT data (0~1), rest is Pred data
        augmentation_config: Augmentation config dict
        ...

    Returns:
        train_loader, val_loader, test_loader
    """
    # Split files
    n_total = len(gt_csv_files)
    n_train = int(n_total * train_ratio)
    n_val = int(n_total * val_ratio)

    train_gt_files = gt_csv_files[:n_train]
    train_pred_files = pred_csv_files[:n_train]
    val_gt_files = gt_csv_files[n_train:n_train+n_val]
    test_gt_files = gt_csv_files[n_train+n_val:]

    # Create datasets with GT/Pred mix
    if gt_ratio >= 1.0:
        # Pure GT
        train_ds = CSVTrajectoryDataset(
            train_gt_files, sequence_length, prediction_length,
            use_gt=True, augmentation_config=augmentation_config
        )
    elif gt_ratio <= 0.0:
        # Pure Pred
        train_ds = CSVTrajectoryDataset(
            train_pred_files, sequence_length, prediction_length,
            use_gt=False, augmentation_config=augmentation_config
        )
    else:
        # Mixed
        n_gt = int(len(train_gt_files) * gt_ratio)
        mixed_gt = train_gt_files[:n_gt]
        mixed_pred = train_pred_files[n_gt:]

        ds_gt = CSVTrajectoryDataset(
            mixed_gt, sequence_length, prediction_length,
            use_gt=True, augmentation_config=augmentation_config
        )
        ds_pred = CSVTrajectoryDataset(
            mixed_pred, sequence_length, prediction_length,
            use_gt=False, augmentation_config=augmentation_config
        )
        train_ds = torch.utils.data.ConcatDataset([ds_gt, ds_pred])

    # Validation and test (always GT, no augmentation)
    val_ds = CSVTrajectoryDataset(
        val_gt_files, sequence_length, prediction_length,
        use_gt=True, augmentation_config=None
    )
    test_ds = CSVTrajectoryDataset(
        test_gt_files, sequence_length, prediction_length,
        use_gt=True, augmentation_config=None
    )

    # Create loaders
    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,
                              num_workers=num_workers, pin_memory=True)
    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False,
                            num_workers=num_workers, pin_memory=True)
    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False,
                             num_workers=num_workers, pin_memory=True)

    print(f"\nCSV Data Loaders Created (GT ratio={gt_ratio:.1%}):")
    print(f"  Train: {len(train_ds)} trajectories")
    print(f"  Val:   {len(val_ds)} trajectories")
    print(f"  Test:  {len(test_ds)} trajectories")

    return train_loader, val_loader, test_loader


# ==================== Loss Functions ====================

class PhaseCoherenceLoss(nn.Module):
    """Phase coherence loss: penalize illegal phase transitions"""
    def __init__(self, weight=10.0):
        super().__init__()
        self.weight = weight
        self.illegal_transitions = {(0, 2), (1, 0), (2, 0), (2, 1)}

    def forward(self, phase_logits):
        B, T, C = phase_logits.shape
        if T < 2:
            return torch.tensor(0.0, device=phase_logits.device)

        phase_pred = torch.argmax(phase_logits, dim=-1)
        loss = 0.0
        count = 0

        for t in range(T - 1):
            phase_t = phase_pred[:, t]
            phase_t1 = phase_pred[:, t+1]

            for b in range(B):
                transition = (int(phase_t[b]), int(phase_t1[b]))
                if transition in self.illegal_transitions:
                    illegal_phase = phase_t1[b]
                    loss += phase_logits[b, t+1, illegal_phase] ** 2
                    count += 1

        return self.weight * loss / count if count > 0 else torch.tensor(0.0, device=phase_logits.device)


class SpeedPenaltyLoss(nn.Module):
    """Speed penalty loss: penalize speed exceeding max_speed_mm_per_frame"""
    def __init__(self, max_speed_mm_per_frame, weight=5.0):
        super().__init__()
        self.max_speed = max_speed_mm_per_frame
        self.weight = weight

    def forward(self, pred_arms):
        B, T, D = pred_arms.shape
        if T < 2:
            return torch.tensor(0.0, device=pred_arms.device)

        velocity = pred_arms[:, 1:] - pred_arms[:, :-1]
        velocity_points = velocity.view(B, T-1, 4, 3)
        speeds = torch.norm(velocity_points, dim=-1)
        penalty = torch.relu(speeds - self.max_speed)

        return self.weight * penalty.pow(2).mean()


class CombinedLoss(nn.Module):
    """Combined loss for CSV trajectory training with phase prediction"""
    def __init__(self, robot_weight=1.0, phase_weight=1.0, coherence_weight=10.0,
                 speed_weight=5.0, max_speed_mm_per_frame=10.0, smooth_vel_weight=0.05, smooth_acc_weight=0.01):
        super().__init__()
        self.robot_weight = robot_weight
        self.phase_weight = phase_weight
        self.coherence_weight = coherence_weight
        self.mse = nn.MSELoss()
        self.ce = nn.CrossEntropyLoss()
        self.phase_coherence_loss_fn = PhaseCoherenceLoss(weight=1.0)  # Base weight=1.0, will multiply by coherence_weight
        self.speed_loss = SpeedPenaltyLoss(max_speed_mm_per_frame=max_speed_mm_per_frame, weight=speed_weight)
        self.smooth_vel_w = smooth_vel_weight
        self.smooth_acc_w = smooth_acc_weight

    def set_phase_weights(self, phase_weight, coherence_weight):
        """Dynamically update phase and coherence weights"""
        self.phase_weight = phase_weight
        self.coherence_weight = coherence_weight

    def forward(self, pred_robot, pred_phase, gt_robot, gt_phase):
        B, T, _ = pred_robot.shape
        device = pred_robot.device

        robot_loss = self.mse(pred_robot, gt_robot)
        pred_phase_flat = pred_phase.reshape(-1, 3)
        gt_phase_flat = gt_phase.reshape(-1)
        phase_loss = self.ce(pred_phase_flat, gt_phase_flat)
        coherence_loss_raw = self.phase_coherence_loss_fn(pred_phase)
        speed_loss = self.speed_loss(pred_robot)
        vel_loss = ((pred_robot[:, 1:] - pred_robot[:, :-1])**2).mean() if T > 1 else torch.tensor(0.0, device=device)
        acc_loss = ((pred_robot[:, 2:] - 2*pred_robot[:, 1:-1] + pred_robot[:, :-2])**2).mean() if T > 2 else torch.tensor(0.0, device=device)

        # Apply dynamic weights to phase and coherence losses
        total_loss = (self.robot_weight * robot_loss +
                     self.phase_weight * phase_loss +
                     self.coherence_weight * coherence_loss_raw +
                     speed_loss +
                     self.smooth_vel_w * vel_loss +
                     self.smooth_acc_w * acc_loss)

        loss_dict = {
            'robot': robot_loss.item(),
            'phase': phase_loss.item(),
            'coherence': coherence_loss_raw.item() if isinstance(coherence_loss_raw, torch.Tensor) else coherence_loss_raw,
            'speed': speed_loss.item() if isinstance(speed_loss, torch.Tensor) else speed_loss,
            'smooth_vel': vel_loss.item() if isinstance(vel_loss, torch.Tensor) else vel_loss,
            'smooth_acc': acc_loss.item() if isinstance(acc_loss, torch.Tensor) else acc_loss,
            'total': total_loss.item()
        }

        return total_loss, loss_dict
